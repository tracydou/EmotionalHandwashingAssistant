"""------------------------------------------------------------------------------------------
Bayesian Affect Control Theory
Assistance Interactive Example
Author: Jesse Hoey  jhoey@cs.uwaterloo.ca   http://www.cs.uwaterloo.ca/~jhoey
September 2013
Use for research purposes only.
Please do not re-distribute without written permission from the author
Any commerical uses strictly forbidden.
Code is provided without any guarantees.
Research sponsored by the Natural Sciences and Engineering Council of Canada (NSERC).
use python2.6
see README for details
----------------------------------------------------------------------------------------------"""

#new verison is bayesactp - use just 'bayesact' to revert to the previous version
#also change in subclasses e.g. assistant.py and pwid.py
from bayesact import *
from assistant import *
from pwid import *


def run_assistant():
    
    def is_array_of_floats(possarray):
        try:
            parr = [float(x) for x in possarray.split(',')]
        except ValueError:
            return False
        if len(parr)==3:
            return parr
        return False

            
        
    #a function to ask the client for an action to take and map it to an EPA value
    def ask_client(fbeh,sugg_act='',epaact=[],qq="behaviour"):
        sst="your action ("+qq+" ... '?' shows options): "

        sstnc="You can now either :\n"
        sstnc+="- pick an action ("+qq+") and type in its label\n"
        sstnc+="- type 'quit' to stop the simulation\n"
        sstnc+="- type a comma separated list of three numbers to specify the action as E,P,A values\n"
        if not sugg_act=='':
            sstnc+="- hit 'enter' to take default action with label: "+sugg_act+"\n"
        if not epaact=='':
            sstnc+="- type any digit (0-9) to take suggsted action: "+str(epaact)

        if do_automatic:
            return epaact

        
        while True:
            cact = raw_input(sst)
            if cact=='quit':
                return []
            elif cact=='' and not sugg_act=='':
                cact=sugg_act
                if qq=="identity":
                    return cact
                break
            elif cact.isdigit() and not epaact==[]:
                return epaact
            elif re.sub(r"\s+","_",cact.strip()) in fbeh.keys():
                cact=re.sub(r"\s+","_",cact.strip()) 
                break
            elif cact=="?":
                print sstnc
            elif is_array_of_floats(cact):
                return [float(x) for x in cact.split(',')]
            else:
                print "incorrect or not found, try again. '?' shows options"
        observ=map(lambda x: float (x), [fbeh[cact]["e"],fbeh[cact]["p"],fbeh[cact]["a"]])
        print "client said: ",cact
        return observ
    
    #NP.set_printoptions(precision=5)
    #NP.set_printoptions(suppress=True)
    NP.set_printoptions(linewidth=10000)
     


    #-----------------------------------------------------------------------------------------------------------------------------
    #user-defined parameters 
    #-----------------------------------------------------------------------------------------------------------------------------
    #agent knowledge of client id: 
    #0 : nothing
    #1 : one of a selection of  num_confusers+1 randoms
    #2 : exactly - use this to mimic interact
    #3 : same as 0 but also agent does not know its own id
    agent_knowledge=2

    # agent gender
    agent_gender="male"

    # client gender
    client_gender="male"

    #possibly set the agent id to be something
    agent_id="assistant"
    #if not in database (including "") then it is a randomly drawn id
    #agent_id=""

    #can also set the client id here if agent_knowledge = 2 (knows id of client - see above)
    #if agent_knowledge is 0 then this is ignored
    client_id = "patient"

    #what is the client really? 
    true_client_id = "patient"
    #true_client_id = "psychotic"
    #client_id = ""

    #initial awareness distribution 0 = aware, 1 = unaware
    initial_px = [0.3,0.7]

    #set to "" to not do a fixed action
    fixed_agent_act=""

    #when there is a fixed agent action, this is the action taken when no prompt
    fixed_agent_default_act="mind"

    if len(sys.argv) > 1:
        true_client_id=sys.argv[1]
    if len(sys.argv) > 2:
        fixed_agent_act=sys.argv[2]
    if len(sys.argv) > 3:
        fixed_agent_default_act=sys.argv[3]


    print "true_client_id: ",true_client_id
    print "fixed_agent_act: ",fixed_agent_act
    print "fixed_agent_default_act: ",fixed_agent_default_act

    #who goes first? 
    initial_learn_turn="client"
    initial_simul_turn="agent"



    num_plansteps=8  #includes the zeroth plan step and the end planstep


    #how often do we want to see the full id sets learned by the agent
    get_full_id_rate=-1


    #do we want to try to mimic interact?
    mimic_interact=False

    #if True, don't ask client just run
    do_automatic=False

    use_pomcp=True

    #parameters for POMCP
    numcact=5  #user defined 
    numdact=(num_plansteps-1)+1  #8 planstep changes  +  1 null action
    obsres=1.0
    actres=1.0
    timeout=10.0

    if not fixed_agent_act=="":
        numdact=1
        numcact=1   ##?? why 1 here - should stay the same at 9?

    print "do_pomcp? :",use_pomcp
    print "pomcp obsres:  ",obsres
    print "pomcp actres:  ",actres
    print "pomcp timeout: ",timeout
    print "pomcp numcact: ",numcact
    print "pomcp numdact: ",numdact

    max_num_iterations=50

    #dictionary giving the state dynamics 
    nextPsDict={0:([0.8,0.2],[2,1]),
                1:([1.0],[3]),
                2:([1.0],[3]),
                3:([1.0],[4]),
                4:([0.8,0.2],[5,6]),
                5:([1.0],[7]),
                6:([1.0],[7]),
                7:([1.0],[7])}

    nextPsDictlinear={0:([1.0],[1]),
                1:([1.0],[2]),
                2:([1.0],[3]),
                3:([1.0],[4]),
                4:([1.0],[5]),
                5:([1.0],[6]),
                6:([1.0],[7]),
                7:([1.0],[7])}



    #-----------------------------------------------------------------------------------------------------------------------------
    #these parameters can be tuned, but using caution
    #-----------------------------------------------------------------------------------------------------------------------------
    #agent's ability to change identities - higher means it will shape-shift more
    bvagent=0.0001
    #agent's belief about the client's ability to change identities - higher means it will shape-shift more
    bvclient=0.0001  #was 0.5

    simul_bvclient=0.001
    simul_bvagent=0.001

    #initial estimates of ids
    #learn_beta_agent_init is given by init_id, the others are overridden here
    agent_learn_beta_client_init=2.0     #0.0001

    #pwd has a vague identity and a rough concept of the identity of the agent
    simul_learn_beta_agent_init=0.0001
    simul_learn_beta_client_init=0.0001

    #-----------------------------------------------------------------------------------------------------------------------------
    #these parameters can be tuned, but will generally work "out of the box" for a basic simulation
    #-----------------------------------------------------------------------------------------------------------------------------

    #behaviours file
    fbfname="fbehaviours.dat"

    #identities file
    fifname="fidentities.dat"

    #get some key parameters from the command line
    #set much larger to mimic interact (>5000)
    num_samples=100


    # use 0.0 for mimic interact simulations
    #roughening_noise=0.0
    roughening_noise=num_samples**(-1.0/3.0)


    #the observation noise
    #set to 0.05 or less to mimic interact
    obs_noise=0.5

    xobsnoise=0.01
    simul_xobsnoise=0.00001

    if mimic_interact:
        #bvagent_init=0.000001
        bvclient_init=0.000001
        #bvagent=0.00001
        bvclient=0.00001
        agent_knowledge=2
        num_samples=100000
        roughening_noise=0.0
        obs_noise=0.01
        num_action_samples=10000


    #do we print out all the samples each time
    learn_verbose=False

    #for repeatability
    rseed = NP.random.randint(0,382948932)
    #rseed=41764004
    #rseed=159199186
    #rseed=167871892
    #rseed=52566448
    rseed=299798854
    print "random seeed is : ",rseed
    NP.random.seed(rseed)

    #-----------------------------------------------------------------------------------------------------------------------------
    #code start - here there be dragons - only hackers should proceed, with caution
    #-----------------------------------------------------------------------------------------------------------------------------

    fbehaviours_agent=readSentiments(fbfname,agent_gender)
    fbehaviours_client=readSentiments(fbfname,client_gender)

    (agent_mean_ids,agent_cov_ids)=getIdentityStats(fifname,agent_gender)
    (client_mean_ids,client_cov_ids)=getIdentityStats(fifname,client_gender)

    #the mean and covariance of IDs for male agents as taken from the databases
    #should do this automatically in python based on actual genders of client/agent....as above now
    #mean_ids=NP.array([0.40760,0.40548,0.45564])
    #$cov_ids=NP.array([[2.10735,1.01121, 0.48442],[1.01121,1.22836,0.55593],[0.48442,0.55593,0.77040]])

    #the actual (true) ids drawn from the distribution over ids, if not set to something in particular
    aid=agent_id
    agent_id=getIdentity(fifname,agent_id,agent_gender)
    if agent_id==[]:
        agent_id=NP.random.multivariate_normal(agent_mean_ids,agent_cov_ids)
    agent_id=NP.asarray([agent_id]).transpose()

    client_id=getIdentity(fifname,client_id,agent_gender)
    if client_id==[]:
        client_id =  NP.random.multivariate_normal(client_mean_ids,client_cov_ids)
    client_id=NP.asarray([client_id]).transpose()


    client_agent_id=getIdentity(fifname,aid,client_gender)
    if client_agent_id==[]:
        client_agent_id=NP.random.multivariate_normal(agent_mean_ids,agent_cov_ids)
    client_agent_id=NP.asarray([client_agent_id]).transpose()



    true_client_id=getIdentity(fifname,true_client_id,client_gender)
    if true_client_id==[]:
        true_client_id =  NP.random.multivariate_normal(client_mean_ids,client_cov_ids)
    true_client_id=NP.asarray([true_client_id]).transpose()

    #get initial sets of parameters for agent
    (learn_tau_init,learn_prop_init,learn_beta_client_init,learn_beta_agent_init)=init_id(agent_knowledge,agent_id,client_id,client_mean_ids)


    (simul_tau_init,simul_prop_init,simul_beta_client_init,simul_beta_agent_init)=init_id(agent_knowledge,true_client_id,client_agent_id,agent_mean_ids)

    #overwrite these values for the interactive script only
    #do this for mimicking interact
    if mimic_interact:
        learn_beta_agent_init=bvagent_init
        learn_beta_client_init=bvclient_init


    if not fixed_agent_act=="":
        fbehv=fbehaviours_agent[fixed_agent_act]
        fixed_agent_aab=[float(fbehv["e"]),float(fbehv["p"]),float(fbehv["a"])]
        print "agent taking fixed action: ",fixed_agent_act," which is ",fixed_agent_aab

        fbehv=fbehaviours_agent[fixed_agent_default_act]
        fixed_agent_default_aab=[float(fbehv["e"]),float(fbehv["p"]),float(fbehv["a"])]
        print "agent taking fixed default action: ",fixed_agent_default_act," which is ",fixed_agent_default_aab
    else:
        print "agent taking bayesact actions"

    #set up fixed policy
    #this is an array fixed_policy[i] giving the affective action to take for 
    #each discrete action available
    fixed_policy=None
    if not fixed_agent_act=="":
        fixed_policy={}
        fixed_policy[0]=mapSentimentLabeltoEPA(fbehaviours_agent,fixed_agent_default_act)

        for a in range(numdact):
            fixed_policy[a+1]=mapSentimentLabeltoEPA(fbehaviours_agent,fixed_agent_act)

    print "fixed policy is: "
    print fixed_policy


    #get the agent - can use some other subclass here if wanted 
    learn_agent=Assistant(N=num_samples,alpha_value=1.0,
                          gamma_value=obs_noise,beta_value_agent=bvagent,beta_value_client=bvclient,
                          beta_value_client_init=agent_learn_beta_client_init,beta_value_agent_init=learn_beta_agent_init,
                          client_gender=client_gender,agent_gender=agent_gender,use_pomcp=use_pomcp,
                          agent_rough=roughening_noise,client_rough=roughening_noise, nextpsd = nextPsDict, onoise=xobsnoise, 
                          fixed_policy=fixed_policy,pomcp_interactive=True,
                          numcact=numcact,numdact=numdact,obsres=obsres,actres=actres,pomcp_timeout=timeout)


    #get the agent - can use some other subclass here if wanted 
    simul_agent=PwD(N=num_samples,alpha_value=1.0,
                    gamma_value=obs_noise,beta_value_agent=simul_bvagent,beta_value_client=simul_bvclient,
                    beta_value_client_init=simul_learn_beta_client_init,beta_value_agent_init=simul_learn_beta_agent_init,
                    client_gender=agent_gender,agent_gender=client_gender,
                    agent_rough=roughening_noise,client_rough=roughening_noise, nextpsd = nextPsDict, onoise=simul_xobsnoise,
                    numcact=numcact,numdact=numdact,obsres=obsres,actres=actres,pomcp_timeout=timeout)

    learn_initx=[initial_learn_turn,initial_px]
    simul_initx=[initial_simul_turn,initial_px]



    print 10*"-","learning agent parameters: "
    learn_agent.print_params()
    print "learner init tau: ",learn_tau_init
    print "learner prop init: ",learn_prop_init
    print "learner beta client init: ",learn_beta_client_init
    print "learner beta agent init: ",learn_beta_agent_init

    print 10*"-","simulated agent parameters: "
    simul_agent.print_params()

    learn_avgs=learn_agent.initialise_array(learn_tau_init,learn_prop_init,learn_initx)

    print "learner (assistant) average sentiments (f) after initialisation: "
    learn_avgs.print_val()

    simul_avgs=simul_agent.initialise_array(simul_tau_init,simul_prop_init,simul_initx)
    print "simulator (pwid) average sentiments (f) after initialisation: "
    simul_avgs.print_val()


    #cval,numaact,numpact,actres,obsres):
    #learn_agent.POMCP_initialise(c_val,numact,num_plansteps+1,actres,obsres,timeout,fixed_policy)
    #learn_agent.POMCP_initialise(c_val,numact,num_plansteps+1,obsres,timeout,fixed_policy)
    #if use_pomcp:
    #    learn_agent.initialise_pomcp(cval,

    learn_turn=initial_learn_turn
    simul_turn=initial_simul_turn    



    done = False
    iter=0
    ps_obs=0
    while not done:
        print 10*"#"," current turn: ",learn_turn," ",10*"#"

        observ=[]
        print 10*"-","iter ",iter,80*"-"




        (learn_aab,learn_paab)=learn_agent.get_next_action(learn_avgs)
        print "agent action/client observ: ",learn_aab        
        simul_observ=learn_aab
        print "agent prop. action: ",learn_paab
        
        (simul_aab,simul_paab)=simul_agent.get_next_action(simul_avgs)
        print "client action/agent observ: ",simul_aab,
        learn_observ=simul_aab
        print "client prop. action: ",simul_paab


        learn_aact=findNearestBehaviour(learn_aab,fbehaviours_agent)
        print "suggested action for the agent is :",learn_aab,"\n  closest label is: ",learn_aact
        print "agent's proposition action : ",learn_paab,"\n"

        simul_aact=findNearestBehaviours(simul_aab,fbehaviours_agent,10)
        print "client's proposition action : ",simul_paab,"\n"
        print "agent advises the following action :",simul_aab,"\n  closest labels are: ", [re.sub(r"_"," ",i.strip()) for i in simul_aact]
            
            
        if learn_turn=="agent":
            learn_aab=ask_client(fbehaviours_agent,learn_aact,learn_aab)
            print "agent does action :",learn_aab,"\n"
            simul_observ=learn_aab
            learn_observ=[]  #awkward
        else:
            #now, this is where the client actually decides what to do, possibly looking at the suggested labels 
            simul_aab=ask_client(fbehaviours_client,simul_aact[0],simul_aab)
            print "client does action: ",simul_aab,"\n"
            learn_observ=simul_aab
            simul_observ=[]  #awkward

        
        #observation of planstep - 
        if do_automatic:
            #really, this would be  - get observation from handtracker and convert to planstep observation
            #here, we use this simple hack to do this automatically, but this won't work in all cases
            ps_obs=simul_paab
        else:
            gotps=False
            while not gotps:
                ps_obs = raw_input("Enter planstep observation (from 0 to "+str(num_plansteps)+") : ")
                try:
                    ps_obs = int(ps_obs)
                    if ps_obs>=0 and ps_obs<num_plansteps:
                        gotps=True
                except ValueError:
                    gotps=False


        if learn_turn=="client" and learn_observ==[]:
            done = True
        elif learn_turn=="agent" and learn_aab==[]:
            done = True
        elif iter > max_num_iterations:
            done = True
        elif simul_agent.is_done():
            print "all done"
            done = True
        else:
            learn_xobs=[State.turnnames.index(invert_turn(learn_turn)),ps_obs]
            learn_avgs=learn_agent.propagate_forward(learn_aab,learn_observ,xobserv=learn_xobs,paab=learn_paab,verb=learn_verbose)

            print "agent f is: "
            learn_avgs.print_val()

            #learn_paab is passed into client as the x-observation
            simul_xobs=[State.turnnames.index(invert_turn(simul_turn)),learn_paab]
            simul_avgs=simul_agent.propagate_forward(simul_aab,simul_observ,xobserv=simul_xobs,paab=None,verb=learn_verbose)

            print "client f is: "
            simul_avgs.print_val()


            #I think these should be based on fundamentals, not transients
            (aid,cid)=learn_agent.get_avg_ids(learn_avgs.f)
            print "agent thinks it is most likely a: ",aid
            print "agent thinks the client is most likely a: ",cid

            (aid,cid)=simul_agent.get_avg_ids(simul_avgs.f)
            print "client thinks it is most likely a: ",aid
            print "client thinks the agent is most likely a: ",cid
            
            print "client state is: "
            simul_agent.print_state()

            if get_full_id_rate>0 and (iter+1)%get_full_id_rate==0:
                (cnt_ags,cnt_cls)=learn_agent.get_all_ids()
                print "agent thinks of itself as (full distribution): "
                print cnt_ags[0:10]
                print "agent thinks of the client as (full distribution): "
                print cnt_cls[0:10]
            iter += 1
        print "current deflection of averages: ",learn_agent.deflection_avg

        print "current deflection of averages (client): ",simul_agent.deflection_avg
                
        learn_d=learn_agent.compute_deflection()
        print "current deflection (agent's perspective): ",learn_d

        simul_d=simul_agent.compute_deflection()
        print "current deflection (client's perspective): ",simul_d
        if learn_turn=="client":
            learn_turn="agent"
        elif learn_turn=="agent":
            learn_turn="client"

        if simul_turn=="client":
            simul_turn="agent"
        elif simul_turn=="agent":
            simul_turn="client"
        

    print "final simul agent state: "
    simul_agent.print_state()

if __name__ == "__main__":
    run_assistant()
